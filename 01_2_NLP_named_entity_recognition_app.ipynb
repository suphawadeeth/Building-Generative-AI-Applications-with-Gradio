{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a Named Entity Recognition app**"
      ],
      "metadata": {
        "id": "1zb5PYPSQY8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are building an app that will take text and label a person's name, institution, or places, etc., using a BERT-based named entity recognition model.\n",
        "\n",
        "- BERT is a machine learning model for natural language processing (NLP).\n",
        "- It extracts or identifies specific entities such as names, places, companies, institutions, etc.\n",
        "- We are using the **bert-base-NER** model, a 108M-parameter fine-tuned BERT model for Named Entity Recognition (NER).\n",
        "\n",
        "**bert-base-NER** recognizes 4 types of entities:\n",
        "\n",
        "- LOC (Location)\n",
        "- ORG (Organization)\n",
        "- PER (Person)\n",
        "- MISC (Miscellaneous)"
      ],
      "metadata": {
        "id": "kotRDtX8RBjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdQ2lsloQWvb"
      },
      "outputs": [],
      "source": [
        "# the code to run the model locally using API endpoint\n",
        "from transformers import pipeline\n",
        "\n",
        "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input)\n",
        "    return {\"text\": input, \"entities\": output}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_api_key = userdata.get('HF_API_KEY')\n",
        "import gradio as gr\n",
        "\n",
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "# Summarization endpoint\n",
        "def get_completion(inputs, parameters=None,ENDPOINT_URL=userdata.get('HF_API_SUMMARY_BASE')):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL, headers=headers,\n",
        "                                data=json.dumps(data)\n",
        "                               )\n",
        "    return json.loads(response.content.decode(\"utf-8\"))\n"
      ],
      "metadata": {
        "id": "EADiLW-CXpuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = userdata.get('HF_API_NER_BASE') #NER endpoint\n",
        "text = \"My name is Andrew and I live in California\"\n",
        "get_completion(text, parameters=None, ENDPOINT_URL=API_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76Y1HTLUmPU",
        "outputId": "ada04233-d3f2-4870-a1b0-3f4c88274b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9872257113456726,\n",
              "  'word': 'Pol',\n",
              "  'start': 11,\n",
              "  'end': 14},\n",
              " {'entity_group': 'PER',\n",
              "  'score': 0.4419715702533722,\n",
              "  'word': '##i',\n",
              "  'start': 14,\n",
              "  'end': 15},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9195873737335205,\n",
              "  'word': 'HuggingFace',\n",
              "  'start': 28,\n",
              "  'end': 39}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we run the get_completion function, we will get a dictionary of entities as a result.\n",
        "\n",
        "But it does not look pretty for the user.\n",
        "\n",
        "Therefore, we use Gradio to make this more user-friendly output."
      ],
      "metadata": {
        "id": "7zdRdk7AbuS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    return {\"text\": input, \"entities\": output}\n",
        "\n",
        "\n",
        "# create a user interface with Gradio\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=3)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Result\")],\n",
        "                    title=\"Names Entity Recognition App\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "tLC2iqhIX07W",
        "outputId": "fb2dedf6-8609-4d7b-d208-3a610fc9bc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://48d2eb8b27b80e8b2d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://48d2eb8b27b80e8b2d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to merge tokens\n",
        "\"\"\"This function will merge tokens (broken words) and present into a complete word\n",
        "    e.g. from 'Pol' + 'i', the result of merge tokens will be 'Poli' as a name\"\"\"\n",
        "\n",
        "\n",
        "def merge_tokens(tokens):\n",
        "    merged_tokens = []\n",
        "    for token in tokens:\n",
        "        if merged_tokens and merged_tokens[-1]['entity_group'].endswith(token['entity_group'][2:]):\n",
        "            # If current token continues the entity of the last one, merge them\n",
        "            last_token = merged_tokens[-1]\n",
        "            last_token['word'] += token['word'].replace('##', '')\n",
        "            last_token['end'] = token['end']\n",
        "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
        "        else:\n",
        "            # Otherwise, add the token to the list\n",
        "            merged_tokens.append(token)\n",
        "    return merged_tokens\n",
        "\n",
        "\n",
        "# call the merged_tokens inside the 'ner' function for our app\n",
        "def ner(input):\n",
        "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
        "    merged_tokens = merge_tokens(output)\n",
        "    return {\"text\": input, \"entities\": merged_tokens}\n",
        "\n",
        "demo = gr.Interface(fn=ner,\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Result\")],\n",
        "                    title=\"Names Entity Recognition App\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "O7_SAkoKfYKr",
        "outputId": "7d7b849c-8241-4a9b-ba09-2dbf9cc56ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://34041899ab52f2a51d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34041899ab52f2a51d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up and close all the ports\n",
        "gr.close_all()"
      ],
      "metadata": {
        "id": "zJf1mNSmbdCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "- How to get Inference API huggingface, see [LINK](https://blog.futuresmart.ai/mastering-hugging-face-inference-api-integrating-nlp-models-for-real-time-predictions)"
      ],
      "metadata": {
        "id": "OFsuS6EObM3R"
      }
    }
  ]
}